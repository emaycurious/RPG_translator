{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "k.after(1000,get_xy)\n",
      "..after(1000,get_xy)\n",
      "ont)\n",
      "abel = Label(tk,text = 'hi')\n",
      "abel.place(x=0, y=0)\n",
      "ER.LCILLEY\n",
      "label = Label(tk,text = 'hi')\n",
      "label. pleeoce\n",
      "_xy)\n",
      "_xy)\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import ImageGrab\n",
    "import time\n",
    "from tkinter import *\n",
    "\n",
    "\n",
    "def get_xy():\n",
    "\n",
    "    w = tk.winfo_width()\n",
    "    h = tk.winfo_height()\n",
    "\n",
    "    x = tk.winfo_x()\n",
    "    y = tk.winfo_y() - h - 20\n",
    "    \n",
    "    # ocr 识别文字\n",
    "    bbox=(x, y, x+w, y+h)\n",
    "    screenshot = ImageGrab.grab(bbox=bbox)\n",
    "    txt = pytesseract.image_to_string(screenshot, lang='eng').strip()\n",
    "\n",
    "    # print(txt)\n",
    "\n",
    "    label.configure(text=txt)\n",
    "\n",
    "    tk.after(1000,get_xy)\n",
    "\n",
    "\n",
    "tk = Tk()\n",
    "tk.geometry('500x100')\n",
    "tk.attributes('-topmost', True)\n",
    "tk.title(' ')\n",
    "label = Label(tk,text = 'hi')\n",
    "label.place(x=0, y=0)\n",
    "label.pack(expand=YES)\n",
    "\n",
    "tk.after(1000,get_xy)\n",
    "\n",
    "tk.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "class Api:\n",
    "    def __init__(self,api,role):\n",
    "        self.model = api[\"model\"]\n",
    "        self.api_key = api[\"api_key\"]\n",
    "        self.base_url = api[\"base_url\"]\n",
    "        self.is_steam = api[\"is_steam\"]\n",
    "        self.role = role\n",
    "\n",
    "        self.client = OpenAI(api_key=self.api_key, base_url=self.base_url)\n",
    "\n",
    "    def talk(self,question):\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.role},\n",
    "                {\"role\": \"user\", \"content\": question}\n",
    "            ],\n",
    "            stream=self.is_steam\n",
    "        )\n",
    "        answer = response.choices[0].message.content\n",
    "        return answer\n",
    "    \n",
    "\n",
    "qwen_plus_api = {\n",
    "\n",
    "    \"model\":\"qwen-plus\",\n",
    "    \"api_key\":\"sk-e30aaee8bcce40348cf790585352bf36\",\n",
    "    \"base_url\":\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    \"is_steam\":False\n",
    "    \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like you.\n"
     ]
    }
   ],
   "source": [
    "api = Api(qwen_plus_api,\"你是一个日漫翻译助手\")\n",
    "need = \"请有感情地翻译下面这句话，翻译后输出英文，不要有多余的句子：\"\n",
    "answer = api.talk(need + \"あなたが好きです\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import ImageGrab\n",
    "import time\n",
    "from tkinter import *\n",
    "import tkinter.font as tkFont\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "class Api:\n",
    "    def __init__(self,api,role):\n",
    "        self.model = api[\"model\"]\n",
    "        self.api_key = api[\"api_key\"]\n",
    "        self.base_url = api[\"base_url\"]\n",
    "        self.is_steam = api[\"is_steam\"]\n",
    "        self.role = role\n",
    "\n",
    "        self.client = OpenAI(api_key=self.api_key, base_url=self.base_url)\n",
    "\n",
    "    def talk(self,question):\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.role},\n",
    "                {\"role\": \"user\", \"content\": question}\n",
    "            ],\n",
    "            stream=self.is_steam\n",
    "        )\n",
    "        answer = response.choices[0].message.content\n",
    "        return answer\n",
    "    \n",
    "\n",
    "qwen_plus_api = {\n",
    "\n",
    "    \"model\":\"qwen-plus\",\n",
    "    \"api_key\":\"sk-e30aaee8bcce40348cf790585352bf36\",\n",
    "    \"base_url\":\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    \"is_steam\":False\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "def translate():\n",
    "\n",
    "    w = tk.winfo_width()\n",
    "    h = tk.winfo_height()\n",
    "\n",
    "    x = tk.winfo_x()\n",
    "    y = tk.winfo_y() - h \n",
    "    \n",
    "    # ocr 识别文字\n",
    "    bbox=(x, y, x+w, y+h)\n",
    "    screenshot = ImageGrab.grab(bbox=bbox)\n",
    "    txt = pytesseract.image_to_string(screenshot, lang='jpn').strip()\n",
    "\n",
    "    # label_1.configure(text=txt)\n",
    "    \n",
    "    # 如果扫描的句子变了，才重新翻译\n",
    "    if len(old_txt)==0:\n",
    "        old_txt.append(txt)\n",
    "    else:\n",
    "        if txt != old_txt[0]:\n",
    "            # translate\n",
    "            answer = api.talk(need + txt)\n",
    "            label.configure(text=answer)\n",
    "            old_txt[0] = txt\n",
    "\n",
    "\n",
    "    tk.after(200,translate)\n",
    "\n",
    "\n",
    "tk = Tk()\n",
    "tk.geometry('1000x200')\n",
    "tk.attributes('-topmost', True)\n",
    "tk.title(' ')\n",
    "\n",
    "# label_1 = Label(tk,text = 'ok',font=(\"fixed\",15))\n",
    "# label_1.pack(expand=YES)\n",
    "\n",
    "label = Label(tk,text = 'hi',font=(\"fixed\",15))\n",
    "label.pack()    # expand=YES\n",
    "\n",
    "api = Api(qwen_plus_api,\"你是一个日漫翻译助手\")\n",
    "need = \"请有感情地翻译下面这句话，翻译后输出中文，注意：看到日语才翻译，其他语言输出...，不要有多余的句子：\" # 看到日语才翻译，其他语言输出...，\n",
    "\n",
    "old_txt = []\n",
    "\n",
    "tk.after(1000,translate)\n",
    "\n",
    "tk.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fangsong ti', 'fixed', 'clearlyu alternate glyphs', 'courier 10 pitch', 'open look glyph', 'bitstream charter', 'song ti', 'open look cursor', 'newspaper', 'clearlyu ligature', 'mincho', 'clearlyu devangari extra', 'clearlyu pua', 'clearlyu', 'clean', 'nil', 'clearlyu arabic', 'clearlyu devanagari', 'gothic', 'clearlyu arabic extra')\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import font\n",
    "\n",
    "root = tk.Tk()\n",
    "print(font.families())  # 打印所有可用字体\n",
    "root.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import ImageGrab\n",
    "import time\n",
    "from tkinter import *\n",
    "import tkinter.font as tkFont\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "import io\n",
    "\n",
    "class Api:\n",
    "    def __init__(self,api,role):\n",
    "        self.model = api[\"model\"]\n",
    "        self.api_key = api[\"api_key\"]\n",
    "        self.base_url = api[\"base_url\"]\n",
    "        self.is_steam = api[\"is_steam\"]\n",
    "        self.role = role\n",
    "\n",
    "        self.client = OpenAI(api_key=self.api_key, base_url=self.base_url)\n",
    "\n",
    "    def talk(self,question):\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.role},\n",
    "                {\"role\": \"user\", \"content\": question}\n",
    "            ],\n",
    "            stream=self.is_steam\n",
    "        )\n",
    "        answer = response.choices[0].message.content\n",
    "        return answer\n",
    "    \n",
    "\n",
    "    def talk_img(self,question,img=None):\n",
    "\n",
    "        file = f\"data:image;base64,{img}\"\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "\n",
    "                {\"role\": \"system\", \n",
    "                 \"content\": [\n",
    "                     {\"type\":\"text\",\"text\": self.role}\n",
    "                ]},\n",
    "\n",
    "                {\"role\": \"user\",\n",
    "                 \"content\": [\n",
    "                    {\"type\": \"text\",\"text\": question},\n",
    "                    {\"type\": \"image_url\",\"image_url\": {\"url\":file},}\n",
    "                ]}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        answer = response.choices[0].message.content\n",
    "        return answer\n",
    "\n",
    "qwen_plus_api = {\n",
    "\n",
    "    \"model\":\"qwen-plus\",\n",
    "    \"api_key\":\"sk-e30aaee8bcce40348cf790585352bf36\",\n",
    "    \"base_url\":\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    \"is_steam\":False\n",
    "    \n",
    "}\n",
    "\n",
    "# 传图片ocr\n",
    "qwen_vl_ocr_plus_api = {\n",
    "\n",
    "    \"model\":\"qwen-vl-ocr-latest\",\n",
    "    \"api_key\":\"sk-e30aaee8bcce40348cf790585352bf36\",\n",
    "    \"base_url\":\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    \"is_steam\":False\n",
    "}\n",
    "\n",
    "\n",
    "def translate():\n",
    "\n",
    "    w = tk.winfo_width()\n",
    "    h = tk.winfo_height()\n",
    "\n",
    "    x = tk.winfo_x()\n",
    "    y = tk.winfo_y() - h \n",
    "    \n",
    "    # ocr 识别文字\n",
    "    bbox=(x, y, x+w, y+h)\n",
    "    screenshot = ImageGrab.grab(bbox=bbox)\n",
    "\n",
    "    img_byte_arr = io.BytesIO()\n",
    "    screenshot.save(img_byte_arr, format='PNG')\n",
    "    img_base64 = base64.b64encode(img_byte_arr.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "    pic_txt= api_ocr.talk_img(need_ocr,img_base64)\n",
    "    # label_1.configure(text=pic_txt)\n",
    "    \n",
    "    # 如果扫描的句子变了，才重新翻译\n",
    "    if len(old_txt)==0:\n",
    "        old_txt.append(pic_txt)\n",
    "    else:\n",
    "        if pic_txt != old_txt[0]:\n",
    "            # translate\n",
    "            answer = api_translate.talk(need_tran + pic_txt)\n",
    "            label.configure(text=answer)\n",
    "            old_txt[0] = pic_txt\n",
    "\n",
    "\n",
    "    tk.after(200,translate)\n",
    "\n",
    "\n",
    "tk = Tk()\n",
    "tk.geometry('1000x200')\n",
    "tk.attributes('-topmost', True)\n",
    "tk.title(' ')\n",
    "\n",
    "# label_1 = Label(tk,text = 'ok',font=(\"fixed\",15))\n",
    "# label_1.pack(expand=YES)\n",
    "\n",
    "label = Label(tk,text = 'hi',font=(\"fixed\",15))\n",
    "label.pack()    # expand=YES\n",
    "\n",
    "api_ocr = Api(qwen_vl_ocr_plus_api,\"你是一个专家\")\n",
    "need_ocr = \"请输出图片里面的文字\"\n",
    "\n",
    "api_translate = Api(qwen_plus_api,\"你是一个日漫翻译助手\")\n",
    "need_tran = \"请有感情地翻译图片里面的文字，翻译后输出中文，注意：不要有多余的句子：\" # 看到日语才翻译，其他语言输出...，\n",
    "\n",
    "\n",
    "old_txt = []\n",
    "\n",
    "tk.after(1000,translate)\n",
    "\n",
    "tk.mainloop()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3d_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
